from langchain_google_genai import ChatGoogleGenerativeAI
from langchain.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
import streamlit as st
import os
import sqlite3
from dotenv import load_dotenv
load_dotenv()

# Define LLM response function
def get_gemini_response(question, prompt):
    model = ChatGoogleGenerativeAI(model='gemini-1.5-pro')
    prompt = ChatPromptTemplate([
        ('system', prompt),
        ('human', question)
    ])
    parser = StrOutputParser()
    chain = prompt | model | parser
    response = chain.invoke({})
    return response

# SQL execution
def read_sql_query(sql, db):
    conn = sqlite3.connect(db)
    cur = conn.cursor()
    cur.execute(sql)
    rows = cur.fetchall()
    conn.commit()
    conn.close()
    return rows

# Load prompt file
prompt = []
with open('database_info.txt') as f:
    prompt.extend(f.readlines())

# Set up page and UI
st.set_page_config(page_title="Gemini SQL Assistant")
st.title("üîç Gemini SQL Assistant")

# --- Use session state to store persistent values ---
if "generated_sql" not in st.session_state:
    st.session_state.generated_sql = None

if "query_result" not in st.session_state:
    st.session_state.query_result = None

question = st.text_input("Ask your question:", key="input")

view_option = st.selectbox("Choose what to display:", ["SQL Query", "Query Result"])

submit = st.button("Submit")

# When user submits a question
if submit and question:
    with st.spinner("Generating SQL from your question..."):
        generated_sql = get_gemini_response(question, prompt)
        st.session_state.generated_sql = generated_sql  # Save to session
        try:
            result = read_sql_query(generated_sql, "Sales.db")
            st.session_state.query_result = result  # Save result
        except Exception as e:
            st.session_state.query_result = f"Error: {e}"

# Show the selected view using stored session state
if st.session_state.generated_sql:
    if view_option == "SQL Query":
        st.subheader("üß† SQL Generated by Gemini")
        st.code(st.session_state.generated_sql, language='sql')

    elif view_option == "Query Result":
        st.subheader("üìä Query Result")
        if isinstance(st.session_state.query_result, str):  # Handle errors
            st.error(st.session_state.query_result)
        elif st.session_state.query_result:
            for row in st.session_state.query_result:
                st.write(row)
        else:
            st.info("No rows returned.")
# This code is a simple Streamlit application that allows users to ask questions about a database and get SQL queries and results in response. It uses the Gemini LLM to generate SQL queries based on user input and SQLite to execute those queries against a database. The application also handles errors gracefully and provides a user-friendly interface for interaction.